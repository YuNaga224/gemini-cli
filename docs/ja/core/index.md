# Gemini CLI Core

Gemini CLI の core パッケージ（`packages/core`）は Gemini CLI のバックエンド部分で、Gemini API との通信、ツールの管理、`packages/cli` から送信されたリクエストの処理を担当します。Gemini CLI の全般的な概要については、[メインドキュメントページ](../index.md)を参照してください。

## このセクションのナビゲーション

- **[Core ツール API](./tools-api.md):** ツールがどのように定義、登録、そしてコアによって使用されるかに関する情報。

## Core の役割

Gemini CLI の `packages/cli` 部分がユーザーインターフェースを提供する一方で、`packages/core` は以下を担当します：

- **Gemini API 相互作用:** Google Gemini API との安全な通信、ユーザープロンプトの送信、モデル応答の受信。
- **プロンプトエンジニアリング:** Gemini モデル用の効果的なプロンプトの構築、会話履歴、ツール定義、`GEMINI.md` ファイルからの指示コンテキストを含む可能性があります。
- **ツール管理・オーケストレーション:**
  - 利用可能なツール（ファイルシステムツール、シェルコマンド実行など）の登録
  - Gemini モデルからのツール使用リクエストの解釈
  - 提供された引数で要求されたツールの実行
  - ツール実行結果を Gemini モデルに返してさらなる処理を行う
- **セッションと状態管理:** 会話状態の追跡、履歴と一貫した相互作用に必要な関連コンテキストを含む。
- **設定:** APIキーアクセス、モデル選択、ツール設定などのコア固有の設定の管理。

## セキュリティ考慮事項

Core はセキュリティにおいて重要な役割を果たします：

- **API キー管理:** `GEMINI_API_KEY` を処理し、Gemini API との通信時に安全に使用されることを保証します。
- **ツール実行:** ツールがローカルシステムと相互作用する場合（例：`run_shell_command`）、コア（とその基盤となるツール実装）は適切な注意を払って実行する必要があり、意図しない変更を防ぐためにサンドボックス機構を含むことがよくあります。

## チャット履歴圧縮

長い会話が Gemini モデルのトークン制限を超えないようにするため、コアにはチャット履歴圧縮機能が含まれています。

会話が設定されたモデルのトークン制限に近づくと、コアはモデルに送信する前に会話履歴を自動的に圧縮します。この圧縮は伝達される情報の観点では無損失になるように設計されていますが、使用される全体的なトークン数を減らします。

各モデルのトークン制限は [Google AI ドキュメント](https://ai.google.dev/gemini-api/docs/models) で確認できます。

## モデルフォールバック

Gemini CLI には、デフォルトの "pro" モデルがレート制限されている場合でも CLI を継続して使用できるようにするモデルフォールバック機構が含まれています。

デフォルトの "pro" モデルを使用中に CLI がレート制限を検出した場合、現在のセッションで自動的に "flash" モデルに切り替わります。これにより、中断することなく作業を継続できます。

## ファイル発見サービス

ファイル発見サービスは、現在のコンテキストに関連するプロジェクト内のファイルを見つける責任があります。これは `@` コマンドや、ファイルにアクセスする必要がある他のツールによって使用されます。

## メモリ発見サービス

メモリ発見サービスは、モデルにコンテキストを提供する `GEMINI.md` ファイルの発見と読み込みを担当します。これらのファイルを階層的に検索し、現在の作業ディレクトリから開始してプロジェクトルートとユーザーのホームディレクトリまで移動します。サブディレクトリも検索します。

これにより、グローバル、プロジェクトレベル、コンポーネントレベルのコンテキストファイルを持つことができ、これらすべてが組み合わされてモデルに最も関連性の高い情報を提供します。

読み込まれた `GEMINI.md` ファイルの内容を `表示`、`追加`、`更新` するには、[`/memory` コマンド](../cli/commands.md) を使用できます。